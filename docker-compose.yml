---
services:

  # Media server
  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - /home/raven/.config/jellyfin/:/config
      - /home/raven/.cache/jellyfin/:/cache
      - /home/raven/Media/movies:/data/movie
      - /home/raven/Media/movies2:/data/movie2
      - /home/raven/Media/tvshows:/data/tv-series
      - /home/raven/Media/anime:/data/anime
      - /home/raven/Media/music:/data/music
    ports:
      - 8096:8096
      - 7359:7359/udp #optional
      - 1900:1900/udp #optional
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    restart: unless-stopped

  # Home page
  homarr:
    container_name: homarr
    image: ghcr.io/ajnart/homarr:latest
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock 
      - /home/raven/.config/homarr/configs:/app/data/configs
      - /home/raven/.config/homarr/icons:/app/public/icons
      - /home/raven/.config/homarr/data:/data
    ports:
      - '7575:7575'
      - '80:7575'

  # resolve cloudflare proxy
  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - LOG_HTML=${LOG_HTML:-false}
      - CAPTCHA_SOLVER=${CAPTCHA_SOLVER:-none}
      - TZ=Asia/Kolkata
    ports:
      - "${PORT:-8191}:8191"
    restart: unless-stopped

  # torrent client
  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
      - WEBUI_PORT=8080
      - TORRENTING_PORT=6881
    volumes:
      - /home/raven/.config/qbittorrent/appdata:/config
      - /home/raven/Downloads:/downloads
      - /home/raven/Media:/Media
    ports:
      - 8080:8080
      - 6881:6881
      - 6881:6881/udp
    restart: unless-stopped

  #radarr - for movies
  radarr:
    image: lscr.io/linuxserver/radarr:latest
    container_name: radarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
    volumes:
      - /home/raven/.config/radarr/:/config
      - /home/raven/Media/movies:/movie
      - /home/raven/Media/movies2:/movie2
      - /home/raven/Downloads/:/downloads/ #optional
    ports:
      - 7878:7878
    restart: unless-stopped

  # sonarr - tv shows
  sonarr:
    image: lscr.io/linuxserver/sonarr:latest
    container_name: sonarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
    volumes:
      - /home/raven/.config/sonarr:/config
      - /home/raven/Media/tvshows:/tv-series
      - /home/raven/Media/anime:/anime
      - /home/raven/Downloads:/downloads #optional
    ports:
      - 8989:8989
    restart: unless-stopped

  # lidarr - music 
  lidarr:
    image: lscr.io/linuxserver/lidarr:latest
    container_name: lidarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
    volumes:
      - /home/raven/.config/lidarr:/config
      - /home/raven/Media/music/:/music/
      - /home/raven/Downloads/:/downloads/
    ports:
      - 8686:8686
    restart: unless-stopped

  # indexer
  prowlarr:
    image: lscr.io/linuxserver/prowlarr:latest
    container_name: prowlarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Asia/Kolkata
    volumes:
      - /home/raven/.config/prowlarr/:/config
    ports:
      - 9696:9696
    restart: unless-stopped

  # good frontend for requesting movies
  jellyseerr:
    image: fallenbagel/jellyseerr:latest
    container_name: jellyseerr
    environment:
      - PUID=1000
      - PGID=1000
      - LOG_LEVEL=debug
      - TZ=Asia/Kolkata
      - PORT=5055 #optional
    ports:
      - 5055:5055
    volumes:
      - /home/raven/.config/jellyseerr:/app/config
    restart: unless-stopped

  # dashboard for performance
  # dash:
  #   image: mauricenino/dashdot:latest
  #   restart: unless-stopped
  #   environment:
  #     DASHDOT_ENABLE_CPU_TEMPS: 'true'
  #   privileged: true
  #   ports:
  #     - '8888:3001'
  #   volumes:
  #     - /:/mnt/host:ro

#
# WARNING: Make sure to use the docker-compose.yml of the current release:
#
# https://github.com/immich-app/immich/releases/latest/download/docker-compose.yml
#
# The compose file on main may not be compatible with the latest release.
  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    extends:
      file: hwaccel.transcoding.yml
      service: nvenc # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    volumes:
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    ports:
      - 2283:2283
    depends_on:
      - redis
      - database
    restart: always

  immich-machine-learning:
    container_name: immich_machine_learning
    # For hardware acceleration, add one of -[armnn, cuda, openvino] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}-cuda
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
      # file: hwaccel.ml.yml
      # service: cuda # set to one of [armnn, cuda, openvino, openvino-wsl] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu
    volumes:
      - model-cache:/cache
    env_file:
      - .env
    restart: always

  redis:
    container_name: immich_redis
    image: docker.io/redis:6.2-alpine@sha256:328fe6a5822256d065debb36617a8169dbfbd77b797c525288e465f56c1d392b
    healthcheck:
      test: redis-cli ping || exit 1
    restart: always

  database:
    container_name: immich_postgres
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: '--data-checksums'
    volumes:
      - ${DB_DATA_LOCATION}:/var/lib/postgresql/data
    healthcheck:
      test: pg_isready --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' || exit 1; Chksum="$$(psql --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' --tuples-only --no-align --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')"; echo "checksum failure count is $$Chksum"; [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m
    command: ["postgres", "-c" ,"shared_preload_libraries=vectors.so", "-c", 'search_path="$$user", public, vectors', "-c", "logging_collector=on", "-c", "max_wal_size=2GB", "-c", "shared_buffers=512MB", "-c", "wal_compression=on"]
    restart: always

volumes:
  model-cache:

